import bs4, requests, webbrowser

LINK = () # qui memorizzo il link per la pagine contenente tutti gli annunci
PRE_LINK_ANNUNCIO = () # qui memorizzo the prefisso di un annuncio, lo usero'per un check

response = requests.get(LINK)
response.raise_for_status() # uso il metodo per vedere se non ci sono stati errori nella richiesta http alla pagina
soup = bs4.BeatifulSoup(response.text, 'html.parser')
# uso il trick per trovare il corrispettivo codice scrollando
div_annunci = soup.find('div', class = (...))
#adesso cerco gli indrizzi nel div, sono in tags a
a_annunci = div_annunci.find_all('a')
#adesso estrapoli i links
for a_annuncio in a_annunci:
  link_annuncio = str(a_annuncio.get('href))
  # qui uso il prefisso memorizzato per prendere solo i link che mi servono
  if PRE_LINK_ANNUNCIO in link_annuncio:
    link_annunci.append(link_annuncio)



# okay adesso memorizzo i risultati cosi quando lancerò il programma di nuovo confronterà e aggiungerà i nuovi urls
f = open('risultati_salvati.txt'.'a')
old_link_annunci = [riga.rstrip('\n') for riga in open('risultati_salvati.txt'')]

#adesso faccio il check
new_link_annunci = []
for link_annuncio in link_annunci:
  if link_annuncio not in old_link_annunci:
    new_link_annunci.append(link_annuncio)
    f.write('%s\n' % link_annuncio)
f.close()
